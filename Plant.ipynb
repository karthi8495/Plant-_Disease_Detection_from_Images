{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c4662ff-5b10-45e6-a77e-57994227233d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shutils\n",
      "  Downloading shutils-0.1.0.tar.gz (2.3 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting configparser (from shutils)\n",
      "  Downloading configparser-7.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: pymysql in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from shutils) (1.1.1)\n",
      "Downloading configparser-7.1.0-py3-none-any.whl (17 kB)\n",
      "Building wheels for collected packages: shutils\n",
      "  Building wheel for shutils (setup.py): started\n",
      "  Building wheel for shutils (setup.py): finished with status 'done'\n",
      "  Created wheel for shutils: filename=shutils-0.1.0-py3-none-any.whl size=3283 sha256=216a26dc0a4e35b89745510cce814d7872de4f72a05cb1e123a4f604383e7b3a\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\42\\9c\\d4\\ab0453013b2a9132735074a219123db607250a21d35ee3f616\n",
      "Successfully built shutils\n",
      "Installing collected packages: configparser, shutils\n",
      "Successfully installed configparser-7.1.0 shutils-0.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install shutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a292c7b-c5b3-4f4b-8af3-82fd2d4e848f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnx\n",
      "  Downloading onnx-1.17.0-cp312-cp312-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from onnx) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from onnx) (4.25.5)\n",
      "Downloading onnx-1.17.0-cp312-cp312-win_amd64.whl (14.5 MB)\n",
      "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/14.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/14.5 MB 1.9 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 1.0/14.5 MB 2.0 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 1.3/14.5 MB 2.0 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 2.1/14.5 MB 2.3 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 2.6/14.5 MB 2.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 3.4/14.5 MB 2.6 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 3.9/14.5 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 4.7/14.5 MB 2.9 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 5.8/14.5 MB 3.0 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 6.6/14.5 MB 3.1 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 7.3/14.5 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 8.4/14.5 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 9.2/14.5 MB 3.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 10.2/14.5 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 11.3/14.5 MB 3.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.1/14.5 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.1/14.5 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.9/14.5 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.5/14.5 MB 3.8 MB/s eta 0:00:00\n",
      "Installing collected packages: onnx\n",
      "Successfully installed onnx-1.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbe9cdcb-85a1-4b99-9ef8-b7f145497878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "\n",
    "import torch\n",
    "import torch.onnx\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import onnx\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aec9345-aef5-4ad4-8404-a82c290b0b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:\n",
      "Apple___Apple_scab\n",
      "Apple___Black_rot\n",
      "Apple___Cedar_apple_rust\n",
      "Apple___healthy\n",
      "Blueberry___healthy\n",
      "Cherry_(including_sour)___healthy\n",
      "Cherry_(including_sour)___Powdery_mildew\n",
      "Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\n",
      "Corn_(maize)___Common_rust_\n",
      "Corn_(maize)___healthy\n",
      "Corn_(maize)___Northern_Leaf_Blight\n",
      "Grape___Black_rot\n",
      "Grape___Esca_(Black_Measles)\n",
      "Grape___healthy\n",
      "Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
      "Orange___Haunglongbing_(Citrus_greening)\n",
      "Peach___Bacterial_spot\n",
      "Peach___healthy\n",
      "Pepper,_bell___Bacterial_spot\n",
      "Pepper,_bell___healthy\n",
      "Potato___Early_blight\n",
      "Potato___healthy\n",
      "Potato___Late_blight\n",
      "Raspberry___healthy\n",
      "Soybean___healthy\n",
      "Squash___Powdery_mildew\n",
      "Strawberry___healthy\n",
      "Strawberry___Leaf_scorch\n",
      "Tomato___Bacterial_spot\n",
      "Tomato___Early_blight\n",
      "Tomato___healthy\n",
      "Tomato___Late_blight\n",
      "Tomato___Leaf_Mold\n",
      "Tomato___Septoria_leaf_spot\n",
      "Tomato___Spider_mites Two-spotted_spider_mite\n",
      "Tomato___Target_Spot\n",
      "Tomato___Tomato_mosaic_virus\n",
      "Tomato___Tomato_Yellow_Leaf_Curl_Virus\n"
     ]
    }
   ],
   "source": [
    "# The path to the main directory \n",
    "main_dir = \"D:\\\\kaggle\\\\working\\\\new_directory\" \n",
    "\n",
    "# List all classes in the main directory\n",
    "classes = [d for d in os.listdir(main_dir) if os.path.isdir(os.path.join(main_dir, d))]\n",
    "\n",
    "# Print the names of the classes\n",
    "print(\"Classes:\")\n",
    "for class_name in classes:\n",
    "    print(class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53031ac4-36d5-4d66-bcb4-631d435eeea6",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f3218ae-7b3a-49db-9338-6fbe19b0bb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'D:\\\\kaggle\\\\working\\\\new_directory'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "926fb310-1839-4fff-b321-0b0a8bb8e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),              # resize all images to 150x150 pixels\n",
    "    transforms.ToTensor(),                      # convert images to PyTorch tensors\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01e98948-4d9b-4977-b281-137a99054d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(dataset_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6e9e1d5-be59-4097-a77d-e524124ac1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple___Apple_scab',\n",
       " 'Apple___Black_rot',\n",
       " 'Apple___Cedar_apple_rust',\n",
       " 'Apple___healthy',\n",
       " 'Blueberry___healthy',\n",
       " 'Cherry_(including_sour)___Powdery_mildew',\n",
       " 'Cherry_(including_sour)___healthy',\n",
       " 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot',\n",
       " 'Corn_(maize)___Common_rust_',\n",
       " 'Corn_(maize)___Northern_Leaf_Blight',\n",
       " 'Corn_(maize)___healthy',\n",
       " 'Grape___Black_rot',\n",
       " 'Grape___Esca_(Black_Measles)',\n",
       " 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)',\n",
       " 'Grape___healthy',\n",
       " 'Orange___Haunglongbing_(Citrus_greening)',\n",
       " 'Peach___Bacterial_spot',\n",
       " 'Peach___healthy',\n",
       " 'Pepper,_bell___Bacterial_spot',\n",
       " 'Pepper,_bell___healthy',\n",
       " 'Potato___Early_blight',\n",
       " 'Potato___Late_blight',\n",
       " 'Potato___healthy',\n",
       " 'Raspberry___healthy',\n",
       " 'Soybean___healthy',\n",
       " 'Squash___Powdery_mildew',\n",
       " 'Strawberry___Leaf_scorch',\n",
       " 'Strawberry___healthy',\n",
       " 'Tomato___Bacterial_spot',\n",
       " 'Tomato___Early_blight',\n",
       " 'Tomato___Late_blight',\n",
       " 'Tomato___Leaf_Mold',\n",
       " 'Tomato___Septoria_leaf_spot',\n",
       " 'Tomato___Spider_mites Two-spotted_spider_mite',\n",
       " 'Tomato___Target_Spot',\n",
       " 'Tomato___Tomato_Yellow_Leaf_Curl_Virus',\n",
       " 'Tomato___Tomato_mosaic_virus',\n",
       " 'Tomato___healthy']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c729ce9-0eb3-403e-a71b-ae94bb1e659b",
   "metadata": {},
   "source": [
    "# Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "629539ab-6468-4127-9159-bbfc1eae624f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx,test_idx = train_test_split(list(range(len(dataset))),test_size=0.3,random_state=42)\n",
    "\n",
    "train_dataset = Subset(dataset,train_idx)\n",
    "test_dataset = Subset(dataset,test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "935b47d0-7838-4c60-94bb-878b0aca1678",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train_dataset,batch_size=15,shuffle=True)\n",
    "testloader = DataLoader(test_dataset,batch_size=15,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a214360-3ee9-4468-81e7-936b49007e92",
   "metadata": {},
   "source": [
    "# Define CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ecf6cd55-b031-46b3-baba-6d1e9ac657ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Classification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Classification,self).__init__()\n",
    "\n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(3,32,kernel_size=3,stride=1,padding=1)  # first Convolutional layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2,stride=2,padding=0)     # first pooling layer\n",
    "        self.conv2 = nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1) # second Convolution layer\n",
    "        self.fc1 = nn.Linear(64*37*37,128)                             # 37 x 37 is the size after pooling\n",
    "        self.fc2 = nn.Linear(128, len(dataset.classes))\n",
    "\n",
    "    def forward(self,x):\n",
    "         x = self.pool(F.relu(self.conv1(x)))\n",
    "         x = self.pool(F.relu(self.conv2(x)))\n",
    "         x = torch.flatten(x,1)                        # flatten all dimensions\n",
    "         x = torch.relu(self.fc1(x))\n",
    "         x = self.fc2(x)\n",
    "         return x\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2bb3850c-024f-44f4-9b6b-98c2c8198224",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_Model  = CNN_Classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b09e1f1a-0976-4610-b9d3-2fb1b859815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(CNN_Model.parameters(),lr=0.001)         #Defines the optimizer, Adam with a learning rate of 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0f6686-e764-4b84-a9f6-87435a7dcea2",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "63044950-c267-4c1f-9523-2e05e25743e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.8594730496406555\n",
      "Epoch 2/10, Loss: 0.368681401014328\n",
      "Epoch 3/10, Loss: 0.07125569880008698\n",
      "Epoch 4/10, Loss: 0.501944899559021\n",
      "Epoch 5/10, Loss: 0.0022129875142127275\n",
      "Epoch 6/10, Loss: 0.5597519874572754\n",
      "Epoch 7/10, Loss: 0.0037620356306433678\n",
      "Epoch 8/10, Loss: 0.0032458750065416098\n",
      "Epoch 9/10, Loss: 0.6228703260421753\n",
      "Epoch 10/10, Loss: 0.22277356684207916\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for images, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = CNN_Model(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95770675-4c00-4c90-bc10-5d61f42d5c03",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ae76e9be-bf84-4858-896d-a1dd161463a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.19 %\n",
      "Precision: 87.7547%\n",
      "Recall: 87.1876%\n",
      "F1-score: 87.2259%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "\n",
    "# Switch to evaluation mode\n",
    "CNN_Model.eval()\n",
    "\n",
    "#Initialize variable for storing predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "#correct and total for accuracy\n",
    "correct=0\n",
    "total=0\n",
    "\n",
    "# No gradients needed during evaluation\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images,labels = data\n",
    "\n",
    "        # Forward pass to get predictions\n",
    "        outputs = CNN_Model(images)\n",
    "        _,predicted = torch.max(outputs.data,1)\n",
    "\n",
    "        # update accuracy calculations\n",
    "        total +=labels.size(0)\n",
    "        correct +=(predicted == labels).sum().item()\n",
    "\n",
    "        # Collect predictions and true labels for other metrics\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = 100 * correct/total\n",
    "print(f'Accuracy: {accuracy:.2f} %')\n",
    "\n",
    "#Calculate precision,recall,and F1_score using sklearn\n",
    "precision = precision_score(all_labels,all_preds,average = 'weighted')\n",
    "recall = recall_score(all_labels,all_preds,average = 'weighted')\n",
    "f1 = f1_score(all_labels,all_preds,average = 'weighted')\n",
    "\n",
    "print(f'Precision: {precision * 100:.4f}%')\n",
    "print(f'Recall: {recall * 100:.4f}%')\n",
    "print(f'F1-score: {f1 * 100:.4f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643e3633-2dfb-4677-b872-f6a7c378e328",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c6cdafcb-c160-4e11-9ff1-fef2de147fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: Tomato___Target_Spot\n"
     ]
    }
   ],
   "source": [
    "# Load a test image and preprocess it\n",
    "img = Image.open(\"D:\\\\GUVI AI & ML\\\\Capstone_Final_Project2_Plant Disease Detection from Images\\\\dataset\\\\New Plant Diseases Dataset(Augmented)\\\\test\\\\test\\\\TomatoHealthy3.JPG\")\n",
    "img = transform(img).unsqueeze(0)  # add batch dimension\n",
    "\n",
    "# pass the image through the model\n",
    "CNN_Model.eval()\n",
    "output = CNN_Model(img)\n",
    "\n",
    "_,predicted = torch.max(output,1)\n",
    "print(f'Predicted Class: {dataset.classes[predicted.item()]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4473866b-5430-4e8e-8253-d68742772691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: Potato___Early_blight\n"
     ]
    }
   ],
   "source": [
    "# Load a test image and preprocess it\n",
    "img = Image.open(\"D:\\\\GUVI AI & ML\\\\Capstone_Final_Project2_Plant Disease Detection from Images\\\\dataset\\\\New Plant Diseases Dataset(Augmented)\\\\test\\\\test\\\\PotatoEarlyBlight2.JPG\")\n",
    "img = transform(img).unsqueeze(0)  # add batch dimension\n",
    "\n",
    "# pass the image through the model\n",
    "CNN_Model.eval()\n",
    "output = CNN_Model(img)\n",
    "\n",
    "_,predicted = torch.max(output,1)\n",
    "print(f'Predicted Class: {dataset.classes[predicted.item()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b8d2cf70-2e13-417d-b46d-5a11499b6600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: Apple___Cedar_apple_rust\n"
     ]
    }
   ],
   "source": [
    "# Load a test image and preprocess it\n",
    "img = Image.open(\"D:\\\\GUVI AI & ML\\\\Capstone_Final_Project2_Plant Disease Detection from Images\\\\dataset\\\\New Plant Diseases Dataset(Augmented)\\\\test\\\\test\\\\AppleCedarRust3.JPG\")\n",
    "img = transform(img).unsqueeze(0)  # add batch dimension\n",
    "\n",
    "# pass the image through the model\n",
    "CNN_Model.eval()\n",
    "output = CNN_Model(img)\n",
    "\n",
    "_,predicted = torch.max(output,1)\n",
    "print(f'Predicted Class: {dataset.classes[predicted.item()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a759b06a-bbc9-462e-bf20-848c4741da74",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(CNN_Model.state_dict(), 'cnn_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d8cb45df-5853-4689-8fe7-508e0c0c11ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_Model.load_state_dict(torch.load(\"D:\\\\GUVI AI & ML\\\\Capstone_Final_Project2_Plant Disease Detection from Images\\\\cnn_model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78816bf-4c06-42bb-8079-94f7e230657b",
   "metadata": {},
   "source": [
    "# Pretrained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689059df-1995-4a40-aedd-f7cde98d621f",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11dbca33-e537-44f9-b1cb-00817b1626ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 1.0485159158706665\n",
      "Epoch 2/5, Loss: 0.09223437309265137\n",
      "Epoch 3/5, Loss: 0.7216312885284424\n",
      "Epoch 4/5, Loss: 0.020727457478642464\n",
      "Epoch 5/5, Loss: 0.9807632565498352\n",
      "Finished Training VGG16\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "# Check if GPU is available and set device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load pre-trained VGG16 Models\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "# transfer model to the GPU\n",
    "vgg16 = vgg16.to(device)\n",
    "\n",
    "# Freeze all the layers\n",
    "for param in vgg16.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the classifier to fit the number of classes in your dataset\n",
    "vgg16.classifier[6] = nn.Linear(4096, len(dataset.classes)) #4096 is oinput to the last layer\n",
    "\n",
    "# Transfer classifier changes to the GPU\n",
    "vgg16.classifier = vgg16.classifier.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(device) # move criterion to GPU\n",
    "optimizer = optim.Adam(vgg16.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in trainloader:\n",
    "        # Transfer images and labels to GPU\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = vgg16(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "print('Finished Training VGG16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b651508-2fc3-43d7-bede-4b9dcf53cd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Switch to evaluation mode\n",
    "vgg16.eval()\n",
    "\n",
    "# Initialize variables for storing predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Correct and total for accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "      \n",
    "        # Forward pass to get predictions\n",
    "        outputs = vgg16(images.to(device))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Update accuracy calculations\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.to(device)).sum().item()\n",
    "        \n",
    "        # Collect predictions and true labels for other metrics\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy: {accuracy:.2f} %')\n",
    "\n",
    "# Calculate precision, recall, and F1-score using sklearn\n",
    "precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f'Precision: {precision * 100:.4f}%')\n",
    "print(f'Recall: {recall * 100:.4f}%')\n",
    "print(f'F1-score: {f1 * 100:.4f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a5a538-6656-4fcf-a383-d00ad7a6e1aa",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05995173-0b82-41a9-80ff-9d44fd4724b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch 1/5, Loss: 19.385351181030273\n",
      "Epoch 2/5, Loss: 0.0\n",
      "Epoch 3/5, Loss: 0.0\n",
      "Epoch 4/5, Loss: 0.0\n",
      "Epoch 5/5, Loss: 77.12576293945312\n",
      "Finished Training AlexNet\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "# Check if GPU is available and set device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Load pre-trained AlexNet model\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "\n",
    "# Transfer model to the GPU\n",
    "alexnet = alexnet.to(device)\n",
    "\n",
    "# Freeze layers if desired\n",
    "for param in alexnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the classifier to fit the number of classes in your dataset\n",
    "alexnet.classifier[6] = nn.Linear(4096, len(dataset.classes))\n",
    "\n",
    "# Transfer classifier changes to the GPU\n",
    "alexnet.classifier = alexnet.classifier.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(device)  # Move loss function to GPU\n",
    "optimizer = optim.Adam(alexnet.parameters(), lr=0.02)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in trainloader:\n",
    "        # Transfer images and labels to GPU\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = alexnet(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "print('Finished Training AlexNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f77c0e12-0082-4116-b7cd-fe45f2824a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.63 %\n",
      "Precision: 88.82%\n",
      "Recall: 87.63%\n",
      "F1-score: 87.72%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Switch to evaluation model\n",
    "alexnet.eval()\n",
    "\n",
    "# Initialize variables for storing predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Correct and total for accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# No gradients needed during evaluation\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "      \n",
    "        # Forward pass to get predictions\n",
    "        outputs = alexnet(images.to(device))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Update accuracy calculations\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.to(device)).sum().item()\n",
    "        \n",
    "        # Collect predictions and true labels for other metrics\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy: {accuracy:.2f} %')\n",
    "\n",
    "# Calculate precision, recall, and F1-score using sklearn\n",
    "precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f'Precision: {precision * 100:.2f}%')\n",
    "print(f'Recall: {recall * 100:.2f}%')\n",
    "print(f'F1-score: {f1 * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71752031-bd37-45ef-99bf-65724177debf",
   "metadata": {},
   "source": [
    "# DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a89fc832-f1d6-4fa3-9c15-571bb0fbc609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to C:\\Users\\Lenovo/.cache\\torch\\hub\\checkpoints\\densenet121-a639ec97.pth\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 30.8M/30.8M [00:18<00:00, 1.74MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4, Loss: 3.9687535762786865\n",
      "Epoch 2/4, Loss: 3.110856056213379\n",
      "Epoch 3/4, Loss: 1.5293303728103638\n",
      "Epoch 4/4, Loss: 0.0\n",
      "Finished Training DenseNet\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "# Check if GPU is available and set device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Load pre-trained DenseNet121 model\n",
    "densenet = models.densenet121(pretrained=True)\n",
    "\n",
    "# Transfer model to the GPU\n",
    "densenet = densenet.to(device)\n",
    "\n",
    "# Freeze all the layers if you don't want to train the convolutional layers (optional)\n",
    "for param in densenet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the classifier to fit the number of classes in your dataset\n",
    "num_ftrs = densenet.classifier.in_features\n",
    "densenet.classifier = nn.Linear(num_ftrs, len(dataset.classes))\n",
    "\n",
    "# Transfer classifier changes to the GPU\n",
    "densenet.classifier = densenet.classifier.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(device)  # Move loss function to GPU\n",
    "optimizer = optim.Adam(densenet.parameters(), lr=0.02)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 4\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in trainloader:\n",
    "        # Transfer images and labels to GPU\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = densenet(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "print('Finished Training DenseNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a5f6d95-074c-4ea5-bf86-c8c5a06e9ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.23 %\n",
      "Precision: 90.14%\n",
      "Recall: 88.23%\n",
      "F1-score: 88.34%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Switch to evaluation model\n",
    "# densenet.eval()\n",
    "\n",
    "# Initialize variables for storing predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Correct and total for accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# No gradients needed during evaluation\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "      \n",
    "        # Forward pass to get predictions\n",
    "        outputs = densenet(images.to(device))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Update accuracy calculations\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.to(device)).sum().item()\n",
    "        \n",
    "        # Collect predictions and true labels for other metrics\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy: {accuracy:.2f} %')\n",
    "\n",
    "# Calculate precision, recall, and F1-score using sklearn\n",
    "precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f'Precision: {precision * 100:.2f}%')\n",
    "print(f'Recall: {recall * 100:.2f}%')\n",
    "print(f'F1-score: {f1 * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1983dde0-5d5f-498c-967a-601afd53a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vgg16.state_dict(), 'vgg16.pth')  \n",
    "torch.save(alexnet.state_dict(), 'alexnet_model.pth') \n",
    "torch.save(densenet.state_dict(), 'densenet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7c9564-badb-4c69-9dca-6f72269fb97b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904b0456-df86-4be4-a18b-a210bf8e3eda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da05fe4-a8b8-4526-8706-92c9313bb8ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2490d5b3-fc42-4b8c-bdc0-97f59317c029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
